{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cc8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38b11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytlink = \"https://www.youtube.com/watch?v=xam2U8loUvA&t=11s\"\n",
    "try:\n",
    "    yt=YouTube(ytlink)\n",
    "except:\n",
    "    print(\"Unable to connect\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7efe3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Stream: itag=\"17\" mime_type=\"video/3gpp\" res=\"144p\" fps=\"8fps\" vcodec=\"mp4v.20.3\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"30fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">, <Stream: itag=\"248\" mime_type=\"video/webm\" res=\"1080p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"247\" mime_type=\"video/webm\" res=\"720p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"244\" mime_type=\"video/webm\" res=\"480p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"243\" mime_type=\"video/webm\" res=\"360p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">, <Stream: itag=\"242\" mime_type=\"video/webm\" res=\"240p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">, <Stream: itag=\"278\" mime_type=\"video/webm\" res=\"144p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"249\" mime_type=\"audio/webm\" abr=\"50kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"250\" mime_type=\"audio/webm\" abr=\"70kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"251\" mime_type=\"audio/webm\" abr=\"160kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618a563e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"30fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">, <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">, <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">, <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.streams.filter(file_extension='mp4',adaptive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e56a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_yt=yt.streams.get_by_itag(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e6ab510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PythonProjs\\\\ytscripting\\\\Demovid.mp4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_yt.download('',\"Demovid.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69629bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f1129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2858fb48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\CondaEnvs\\lib\\site-packages\\whisper\\transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(r\"D:\\PythonProjs\\ytscripting\\Demovid.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda32c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is Ritesh Renewation and welcome to my channel in this video. Let's look at how we can make use of whisper Which is a general purpose speech recognition model from open AI to actually transcribe a YouTube video Okay, let's jump into the code So I've already created a collab notebook over here for this you need this pi tube Library Python library for downloading the YouTube video, okay? So that's what I do over here From pi tube I import YouTube and here is the video which I'm trying to actually transcribe Okay, so that is the link of the video. I create a YouTube object right for downloading the video and What I do is that I try to get the filters for this particular link Especially MP4 files. So these are the various streams right in that particular video From this I pull out this particular stream over here and I download the MP4 audio file, okay, that's what I do over here right so once I download the YouTube video over here what I do next is that I have to install the Open AI whisper which is the general purpose speech recognition model, okay? That is what I do over here and then Just three these three lines of code is enough for me to transcribe the audio into text Okay, all I have to do is import whisper create a model, okay? whisper-trotlord model base and then model dot transcribe I pass the audio file which I have downloaded Okay, and here you can see the result Right, let's look at the result, okay? For this video I find this result to be very good when compared to previously I had done a video of transcribing a YouTube video using hugging face basically the Wave to vex models from meta okay using hugging face libraries But this result is much better than that and if I look at this result Right, what I see is that some words have been missed For example over here in this video, let's look at image in is what I tried and its image over here a new AI System from Google brain. So this is correct. So it says so what does Image and do that was a text so somewhere that has been missed over here it takes as an input image and text, okay? But otherwise this doesn't excel and job and the quality of transcription over here the speech to text recognition is Excellent and it is quite fast as well. So for example if I were to run this again Okay, you would see that the results are quiet it the results come in a very fast manner Okay, and the quality of this transcription is too good Okay, and I find it much better than some existing libraries which I have tried and this is open source right the model has been released and you can try out So with these three lines of code you are able to actually transcribe any audio file Right, so in this way I have actually now transcribed a YouTube video I've converted a YouTube video into text Okay, using open AI whisper now. Let's look at the open AI whisper a little bit, okay? So what is open AI whisper? It is a general purpose speech recognition model It is trained on a large data set of diverse audio and is also a multi-task model that can perform multi-lingual speech recognition as well as speech translation and language identification, okay, so if you look at the architecture over here It is a transformer based encoder decoder architecture Right, so you have this multi-task training data. It could be English transcription non-English transcription Right no speech. Some of this is your training data. It's converted the audio is converted to a log mel's Spectogram and it is given as an input to this particular, you know transformer model Okay, so and here they've given examples of that multi-task training format Okay, so a transformer is a sequence to sequence model It is trained on various speech processing tasks including multi-lingual speech Regumissions speech translations spoken language identification and voice activity detection All of these tasks are jointly represented as sequence of tokens to be predicted by the decoder Allowing for a single model to replace many stages of a traditional speech processing pipeline The multi-task training format it uses a set of tokens that serve as task specifiers or classification targets Okay, so this is the model the paper is also there probably you can look at the paper I might make a video on the paper as well in the future, but for the time being this is an excellent Speech recognition engine, okay, and I'm quite impressed with its performance And it is very simple to set up as well as with just three lines of Python code You will be able to convert any audio into text I hope this short video on how you can transcribe by YouTube video Using whisper is useful for you if you like the video, please like share subscribe to the channel. See you in another video Happy learning\n"
     ]
    }
   ],
   "source": [
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b94595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
